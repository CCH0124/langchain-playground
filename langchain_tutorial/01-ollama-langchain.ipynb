{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ecb668",
   "metadata": {},
   "source": [
    "## LangChain: Models, Prompts and Output Parsers\n",
    "### Outline\n",
    "- Direct API calls to Ollama\n",
    "- API calls through LangChain:\n",
    "    - Prompts\n",
    "    - Models\n",
    "    - Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f98bc",
   "metadata": {},
   "source": [
    "## Ollama Install\n",
    "[ollama docker-image | ollama ](https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image)\n",
    "\n",
    "```bash\n",
    "sudo nvidia-ctk runtime configure --runtime=docker\n",
    "sudo systemctl restart docker\n",
    "```\n",
    "```bash\n",
    "docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n",
    "docker exec -it ollama ollama run llama3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffae20",
   "metadata": {},
   "source": [
    "```bash\n",
    "%pip install langchain-ollama\n",
    "%pip install python-dotenv\n",
    "%pip install langchain langchain-core\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95441ce7",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46cb4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaLLM(model='llama3', temperature=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "chat = OllamaLLM(temperature=0.0, model=\"llama3\")\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76360b",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0e8515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "621355c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d02c839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9057b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dde8ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"\n",
    "English\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "你好嗎\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d206d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n",
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25e30828",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_response = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe7e9a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text you provided, `你好嗎`, is in Chinese.\n",
      "\n",
      "Translated to English, it means:\n",
      "\n",
      "\"Hello? How are you?\"\n"
     ]
    }
   ],
   "source": [
    "print(customer_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cceedb",
   "metadata": {},
   "source": [
    "1. Prompts 可以很長和很仔細描述\n",
    "2. 好的 Prompt 是可以被重複使用\n",
    "\n",
    "特別是透過設計好的 prompt template，配合特定關鍵詞來執行類似「思考－行動－觀察」的邏輯流程（稱為 ReAct 框架）。\n",
    "\n",
    "```\n",
    "Question: ...\n",
    "Thought: ...         ← 想法\n",
    "Action: ...          ← 執行某個動作（如搜尋、查資料）\n",
    "Observation: ...     ← 根據動作得到的觀察結果\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a747e3d",
   "metadata": {},
   "source": [
    "## Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3ccc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"thought\", description=\"The reasoning step\"),\n",
    "    ResponseSchema(name=\"action\", description=\"The next action to take\"),\n",
    "    ResponseSchema(name=\"observation\", description=\"Observation from the action\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6150dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bce106e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"thought\": string  // The reasoning step\n",
      "\t\"action\": string  // The next action to take\n",
      "\t\"observation\": string  // Observation from the action\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0fb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['format_instructions', 'question'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'question'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s question step-by-step using ReAct format.\\n\\nCaculator math. But except multiplication and div.\\n\\nOutput Example:\\n\\n```json\\n{{\\n  \"thought\": \"I need to compute 1 + 1\",\\n  \"action\": \"Calculate[1 + 1]\",\\n  \"observation\": \"2\"\\n}}\\n```\\n\\nQuestion: {question}\\n\\n{format_instructions}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "react_template=\"\"\"\n",
    "Answer the user's question step-by-step using ReAct format.\n",
    "\n",
    "Caculator math. But except multiplication and div.\n",
    "\n",
    "Output Example:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"thought\": \"I need to compute 1 + 1\",\n",
    "  \"action\": \"Calculate[1 + 1]\",\n",
    "  \"observation\": \"2\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "# LangChain（底層是 Jinja-like 模板）允許你透過 {{ 與 }} 來逃逸 {}\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=react_template)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a10e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt.format_messages(\n",
    "                    question=\"What is number for 1 + 1\",\n",
    "                    format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d66d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "781e5762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the answer in ReAct format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"thought\": \"I need to compute 1 + 1\",\n",
      "  \"action\": \"Calculate[1 + 1]\",\n",
      "  \"observation\": \"2\"\n",
      "}\n",
      "```\n",
      "\n",
      "Let me know if you have any further questions!\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b65db3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "output_dict = output_parser.parse(result)\n",
    "type(output_dict)\n",
    "print(output_dict.get('observation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784503b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
