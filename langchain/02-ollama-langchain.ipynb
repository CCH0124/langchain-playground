{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fad788",
   "metadata": {},
   "source": [
    "## Memory\n",
    "Large Language Models 是 'stateless'\n",
    "- 每個對話是獨立的\n",
    "- LLM 不會自動記得你前面說過什麼\n",
    "\n",
    "對話機器人看起來「有記憶」，其實是因為：\n",
    "- 系統每次都把完整對話內容重新送進模型當作 context（上下文）\n",
    "- 模型只是「讀了過去說過的話」，再根據上下文回答\n",
    "\n",
    "1. LLM 本身無記憶。每輪互動都需要提供上下文\n",
    "2. Memory 的目的是。幫你自動儲存、累積、注入上下文\n",
    "3. LangChain 設計。把「記憶」模組化，方便 plug-in 使用\n",
    "\n",
    "由於對話長度累加逐漸拉長後會增加記憶體的使用量，使 LLM 的計算成本逐漸提高，如果無限制的保存所有的對話內容顯然代價是昂貴的，因此Langchain中還提供以下幾種記憶體緩衝方式來保存對話內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52195da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaLLM(model='llama3', temperature=0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "chat = OllamaLLM(temperature=0.0, model=\"llama3\")\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory, BaseModel\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate,  MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
    "\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add a list of messages to the store\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant who's good at {ability}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = prompt | chat\n",
    "store = {}\n",
    "\n",
    "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "\n",
    "# RunnableWithMessageHistory(\n",
    "#     chain, #  LLMChain / pipe\n",
    "#     get_by_session_id, # Callback，根據 session_id 回傳 Memory 實例\n",
    "#     input_messages_key=\"input\", # 是 user 輸入（對話訊息）\n",
    "#     history_messages_key=\"chat_history\",#  prompt 中接收歷史訊息的變數名稱\n",
    "#     history_factory_config=[] #  可選，傳給 memory 建構函數的參數，即 Callback\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295cb9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine is a fundamental concept in mathematics, and I'm happy to help you understand it.\n",
      "\n",
      "In simple terms, the cosine of an angle (usually represented by the symbol cos) is a value that describes how much of the angle is \"up\" or \"down\" from the horizontal. Think of it like this: if you're standing on a hill, the cosine would tell you how steep the hill is.\n",
      "\n",
      "Mathematically, the cosine of an angle θ (theta) is defined as:\n",
      "\n",
      "cos(θ) = adjacent side / hypotenuse\n",
      "\n",
      "In a right triangle with angles θ, φ, and γ, the cosine of θ is equal to the length of the adjacent side divided by the length of the hypotenuse.\n",
      "\n",
      "For example, if you have a right triangle with an angle of 30 degrees (π/6 radians), the cosine of that angle would be approximately 0.866 (or √3/2). This means that the angle is \"up\" about 86.6% from the horizontal.\n",
      "\n",
      "Cosine has many practical applications in fields like physics, engineering, and computer graphics, where it's used to calculate distances, angles, and shapes. It's also a fundamental concept in trigonometry, which is the study of triangles and their relationships.\n",
      "\n",
      "Do you have any specific questions or scenarios where you'd like to apply cosine? I'm here to help!\n"
     ]
    }
   ],
   "source": [
    "print(chain_with_history.invoke(\n",
    "    {\"ability\": \"math\", \"question\": \"What does cosine mean?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"foo\"}}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493c7613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': InMemoryHistory(messages=[HumanMessage(content='What does cosine mean?', additional_kwargs={}, response_metadata={}), AIMessage(content='Cosine is a fundamental concept in mathematics, and I\\'m happy to help you understand it.\\n\\nIn simple terms, the cosine of an angle (usually represented by the symbol cos) is a value that describes how much of the angle is \"up\" or \"down\" from the horizontal. Think of it like this: if you\\'re standing on a hill, the cosine would tell you how steep the hill is.\\n\\nMathematically, the cosine of an angle θ (theta) is defined as:\\n\\ncos(θ) = adjacent side / hypotenuse\\n\\nIn a right triangle with angles θ, φ, and γ, the cosine of θ is equal to the length of the adjacent side divided by the length of the hypotenuse.\\n\\nFor example, if you have a right triangle with an angle of 30 degrees (π/6 radians), the cosine of that angle would be approximately 0.866 (or √3/2). This means that the angle is \"up\" about 86.6% from the horizontal.\\n\\nCosine has many practical applications in fields like physics, engineering, and computer graphics, where it\\'s used to calculate distances, angles, and shapes. It\\'s also a fundamental concept in trigonometry, which is the study of triangles and their relationships.\\n\\nDo you have any specific questions or scenarios where you\\'d like to apply cosine? I\\'m here to help!', additional_kwargs={}, response_metadata={})])}\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9ebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think there might be some confusion! You asked what cosine means, and I provided an explanation. Then, you asked \"1 + 1\", which is a basic arithmetic operation.\n",
      "\n",
      "If you meant to ask about the result of 1 + 1, the answer is simply 2!\n",
      "\n",
      "However, if you'd like to explore how cosine fits into this equation or apply it to a specific scenario, I'm here to help. Just let me know!\n"
     ]
    }
   ],
   "source": [
    "print(chain_with_history.invoke(\n",
    "    {\"ability\": \"math\", \"question\": \"1 + 1\"},\n",
    "    config={\"configurable\": {\"session_id\": \"foo\"}}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ecc27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': InMemoryHistory(messages=[HumanMessage(content='What does cosine mean?', additional_kwargs={}, response_metadata={}), AIMessage(content='Cosine is a fundamental concept in mathematics, and I\\'m happy to help you understand it.\\n\\nIn simple terms, the cosine of an angle (usually represented by the symbol cos) is a value that describes how much of the angle is \"up\" or \"down\" from the horizontal. Think of it like this: if you\\'re standing on a hill, the cosine would tell you how steep the hill is.\\n\\nMathematically, the cosine of an angle θ (theta) is defined as:\\n\\ncos(θ) = adjacent side / hypotenuse\\n\\nIn a right triangle with angles θ, φ, and γ, the cosine of θ is equal to the length of the adjacent side divided by the length of the hypotenuse.\\n\\nFor example, if you have a right triangle with an angle of 30 degrees (π/6 radians), the cosine of that angle would be approximately 0.866 (or √3/2). This means that the angle is \"up\" about 86.6% from the horizontal.\\n\\nCosine has many practical applications in fields like physics, engineering, and computer graphics, where it\\'s used to calculate distances, angles, and shapes. It\\'s also a fundamental concept in trigonometry, which is the study of triangles and their relationships.\\n\\nDo you have any specific questions or scenarios where you\\'d like to apply cosine? I\\'m here to help!', additional_kwargs={}, response_metadata={}), HumanMessage(content='1 + 1', additional_kwargs={}, response_metadata={}), AIMessage(content='I think there might be some confusion! You asked what cosine means, and I provided an explanation. Then, you asked \"1 + 1\", which is a basic arithmetic operation.\\n\\nIf you meant to ask about the result of 1 + 1, the answer is simply 2!\\n\\nHowever, if you\\'d like to explore how cosine fits into this equation or apply it to a specific scenario, I\\'m here to help. Just let me know!', additional_kwargs={}, response_metadata={})])}\n"
     ]
    }
   ],
   "source": [
    "print(store) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbe3aca",
   "metadata": {},
   "source": [
    "## trim_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce69e5",
   "metadata": {},
   "source": [
    "```python\n",
    "%pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5817c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,         # 機器人（LLM）說的話\n",
    "    BaseMessage,       # 所有 message 類型的基底 class\n",
    "    HumanMessage,      # 使用者說的話\n",
    "    SystemMessage,     # 系統設定（如角色、規則）\n",
    "    trim_messages,     # 用來修剪過長的 message（避免超過 token 限制）。使用 trim_messages 來實現保留對話的最後 n 個訊息的邏輯。當訊息數量超過 n 時，它將刪除最舊的訊息。\n",
    "                        # https://python.langchain.com/api_reference/core/messages/langchain_core.messages.utils.trim_messages.html\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"you're a good assistant, you always respond with a joke.\"), # 系統設定\n",
    "    HumanMessage(\"i wonder why it's called langchain\"), # 使用者說的話\n",
    "    AIMessage(\n",
    "        'Well, I guess they thought \"WordRope\" and \"SentenceString\" just didn\\'t have the same ring to it!'\n",
    "    ), # LLM 說的話\n",
    "    HumanMessage(\"and who is harrison chasing anyways\"), # 使用者說的話\n",
    "    AIMessage(\n",
    "        \"Hmmm let me think.\\n\\nWhy, he's probably chasing after the last cup of coffee in the office!\"\n",
    "    ), # LLM 說的話\n",
    "    HumanMessage(\"why is 42 always the answer?\"),\n",
    "    AIMessage(\n",
    "        \"Because it’s the only number that’s constantly right, even when it doesn’t add up!\"\n",
    "    ),\n",
    "    HumanMessage(\"What did the cow say?\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0daf7bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "you're a good assistant, you always respond with a joke.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "why is 42 always the answer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Because it’s the only number that’s constantly right, even when it doesn’t add up!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did the cow say?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ollama_token_counter(message):\n",
    "    # 將 BaseMessage 轉成 string\n",
    "    text = message.content if hasattr(message, \"content\") else str(message)\n",
    "    return chat.get_num_tokens(text)\n",
    "\n",
    "\"\"\"\n",
    "Like ConversationTokenBufferMemory \n",
    "\"\"\"\n",
    "selected_messages_token_buffer = trim_messages(\n",
    "    messages,           # 原始訊息清單（HumanMessage / AIMessage / SystemMessage 等）\n",
    "    #使用 Ollama 真正的 token 計算方式來量化訊息長度（非 len()）\n",
    "    #可準確控制 token 負載，避免超過模型輸入限制（例如 LLaMA2 約 4096 tokens）\n",
    "    token_counter=ollama_token_counter,\n",
    "    # 整體訊息最大可用 token 數，數值可能是 512、1024、或 2048 等\n",
    "    # 裁切會從最後一條開始往前加，加到總 token <=  max_tokens 為止\n",
    "    max_tokens=128,       # 最多 token 量\n",
    "    strategy=\"last\",    # 裁切策略：保留最後幾條（最新的對話）\n",
    "    # Most chat models expect that chat history starts with either:\n",
    "    # (1) a HumanMessage or\n",
    "    # (2) a SystemMessage followed by a HumanMessage\n",
    "    # start_on=\"human\" makes sure we produce a valid chat history\n",
    "    start_on=\"human\",   # 對話歷史必須從 HumanMessage 開始（符合多數模型格式要求）\n",
    "    # Usually, we want to keep the SystemMessage\n",
    "    # if it's present in the original history.\n",
    "    # The SystemMessage has special instructions for the model.\n",
    "    include_system=True,# 如果原始訊息有 SystemMessage，就保留它（用於角色設定）\n",
    "    allow_partial=False # 不允許只保留一部分訊息（訊息要完整裁切）\n",
    ")\n",
    "\n",
    "for msg in selected_messages_token_buffer:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e382eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "you're a good assistant, you always respond with a joke.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "why is 42 always the answer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Because it’s the only number that’s constantly right, even when it doesn’t add up!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did the cow say?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Like ConversationBufferWindowMemory  \n",
    "\"\"\"\n",
    "selected_messages_buffer_windows = trim_messages(\n",
    "    messages,           # 原始訊息清單（HumanMessage / AIMessage / SystemMessage 等）\n",
    "    token_counter=len, # 使用 Python 的 len() 函式\n",
    "    max_tokens=5,       # 最多保留 5 則訊息\n",
    "    strategy=\"last\",    # 裁切策略：保留最後幾條（最新的對話）\n",
    "    # Most chat models expect that chat history starts with either:\n",
    "    # (1) a HumanMessage or\n",
    "    # (2) a SystemMessage followed by a HumanMessage\n",
    "    # start_on=\"human\" makes sure we produce a valid chat history\n",
    "    start_on=\"human\",   # 對話歷史必須從 HumanMessage 開始（符合多數模型格式要求）\n",
    "    # Usually, we want to keep the SystemMessage\n",
    "    # if it's present in the original history.\n",
    "    # The SystemMessage has special instructions for the model.\n",
    "    include_system=True,# 如果原始訊息有 SystemMessage，就保留它（用於角色設定）\n",
    "    allow_partial=False # 不允許只保留一部分訊息（訊息要完整裁切）\n",
    ")\n",
    "\n",
    "for msg in selected_messages_token_buffer:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d971121",
   "metadata": {},
   "source": [
    "## 參考\n",
    "- https://myapollo.com.tw/blog/langchain-configure-chain-at-runtime/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
